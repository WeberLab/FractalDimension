{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:45: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SCI_PILOT SIGNAL- 317 POINTS\n",
    "import os \n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#load sample slice and convert to np array\n",
    "example_slice = 'SCI_Pilot_08/SCI_Pilot_08_fMRI_Slice.nii.gz'\n",
    "slice_img = nib.load(example_slice, mmap=False)\n",
    "slice_array = slice_img.get_fdata()\n",
    "slice_sq = np.squeeze(slice_array)\n",
    "#images of slice:\n",
    "#imgplot = plt.imshow(slice_sq[:,:,1])\n",
    "#imgplot = plt.imshow(slice_sq[:,:,1],cmap='Greys',  interpolation='nearest')\n",
    "\n",
    "#initialize empty output arrays and for-loop ranges\n",
    "[N1,N2,_] = slice_sq.shape\n",
    "Hurst = np.zeros((N1,N2))\n",
    "Class = np.zeros((N1,N2)) #uncomment if want class output \n",
    "row = np.arange(0,N1)\n",
    "column = np.arange(0,N2)\n",
    "\n",
    "#gets Hurst coefficient and class for every pixel in slice\n",
    "for i in row:http://localhost:8888/notebooks/Desktop/WeberLab/FractalDimension/FracTool_Bandpass_Filter.ipynb#\n",
    "    for j in column: \n",
    "        rawbold = (slice_sq[i,j,:])\n",
    "        output = FracTool(rawbold, 2.4)\n",
    "        Class[i,j] = output[0] #uncomment if want class output\n",
    "        Hurst[i,j] = output[1]       \n",
    "\n",
    "#heat map of hurst and class\n",
    "Hurst_map = sns.heatmap(Hurst)\n",
    "plt.show()\n",
    "Class_map = sns.heatmap(Class) \n",
    "plt.show()\n",
    "#test on one voxel\n",
    "#print(slice_sq[0,0,:])\n",
    "FracTool(slice_sq[25,25,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:45: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BANDPASS FILTER \n",
    "import os \n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "#load sample slice and convert to np array\n",
    "example_slice = 'SCI_Pilot_08/SCI_Pilot_08_fMRI_Slice.nii.gz'\n",
    "slice_img = nib.load(example_slice, mmap=False)\n",
    "slice_array = slice_img.get_fdata()\n",
    "slice_sq = np.squeeze(slice_array)\n",
    "raw_sig = slice_sq[25,25,:]\n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "filtered_sig = butter_bandpass_filter(raw_sig, 0.01, 0.1, 2.4)\n",
    "\n",
    "FracTool(filtered_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "def Window(ts):\n",
    "    '''This function applies a parabolic window to the signal input'''\n",
    "    n = len(ts) #n is length of time series\n",
    "    W = np.zeros((n,1)) #initialize empty array\n",
    "    #create parabola from 0 to length n\n",
    "    for j in np.arange(0,n):\n",
    "        W[j] = 1 - np.power((2*(j + 1)/(n+1)-1),2)\n",
    "    #multiply parabola and signal to get windowed signal (result)\n",
    "    result = ts * W \n",
    "    return result\n",
    "\n",
    "def Bridge(ts):\n",
    "    '''This function bridge detrends the signal input ts\n",
    "    The function subtracts a line connecting the first and last points from the signal'''\n",
    "    n = len(ts)\n",
    "    #points is the length of the time series from n-1 to 0 (backwards i.e. n-1, n-2,...0)\n",
    "    points = np.arange(n-1, -1, -1).reshape(1,n)\n",
    "    #line is a straight line connecting first and last point\n",
    "    line = ((ts[0]-ts[n-1])*points/(n-1))+ts[n-1]\n",
    "    line = line.transpose() #transposes line from row to column array\n",
    "    #subtract line from time series to return bridge detrended signal (result)\n",
    "    result = ts - line\n",
    "    return result \n",
    "\n",
    "def Linreg(x,y):\n",
    "    '''This function calculates the slope and correlation coefficient of a linear fit model\n",
    "    result[0]: Slope\n",
    "    result[1]: Correlation coefficient'''\n",
    "    #calculate mean of x and y (lgfrek and lgPyy when called in FracTool)\n",
    "    mikro = np.mean(x) #mean of lgfrek\n",
    "    nu = np.mean(y) #mean of lgPyy\n",
    "    mikro_sub = x - mikro #subtract lgfrek mean from lgfrek array \n",
    "    nu_sub = y - nu #subtract lgPyy mean from lgPyy array\n",
    "    #multiply mean-subtracted arrays and add sum of elements \n",
    "    Qxy = np.sum(mikro_sub*nu_sub)\n",
    "    Qx = sum(mikro_sub**2) #sum of sqaured differences of lgfrek\n",
    "    Qy = sum((nu_sub**2)) #sum of squared differences of lgPyy\n",
    "    result = np.empty([2,1]) #initialize empty result array\n",
    "    result[0] = Qxy/Qx #slope of linear regression\n",
    "    result[1] = Qxy/(Qx*Qy)**0.5 #correlation coefficient of linear regression\n",
    "    \n",
    "    return result\n",
    " \n",
    "    \n",
    "def Spec(ts, p, avg): \n",
    "    '''This function performs a spectral analysis of the time series\n",
    "    where ts is the time series, p is the nth power of 2 where 2^n<=length\n",
    "    of time series. If avg=0, then spectra for all, if avg=1, then spectra avg.\n",
    "    An array of the following results will be returned.\n",
    "    result[0]: Hurst coefficient\n",
    "    result[1]: correlation coefficient\n",
    "    result[2]: beta from Fourier analysis\n",
    "    result[3]: Hurst coefficient (high freq excluded)\n",
    "    result[4]: correlation coefficient (high freq excluded)\n",
    "    result[5]: beta from Fourier analysis (high freq excluded)'''\n",
    "    #initialize empty array for results outlined above\n",
    "    result = np.empty([6,1])\n",
    "    f = 1\n",
    "    n = 2**p #p is the greatest integer where 2^p < n \n",
    "    \n",
    "    #compute the estimated power of time series (Pyy):\n",
    "    \n",
    "    #compute the discrete fourier transform of time series \n",
    "    Y = scipy.fftpack.fft(ts.flatten()) #time series needs to be 1D (flattened from 2D)\n",
    "    Y_conj = Y.conj() #return conjucate of every element in Y, eg. conj() of a+bi is a-bi\n",
    "    Pyy = Y*Y_conj/n #multiply Y by conj of Y to get absolute value of Y, squared, then divide by length\n",
    "    Pyy = Pyy[0:int(n/2)] #splice array to only include have first half (it is symmetric)\n",
    "    Pyy = np.reshape(Pyy, (Pyy.size,1)) #convert Pyy to column array\n",
    "    \n",
    "    #clear arrays that are no longer used\n",
    "    Y = []\n",
    "    Y_conj = []\n",
    "    y = []\n",
    "    \n",
    "    #generate array of frequencies from 0 to 0.5 (frek)\n",
    "    frek = f/n*np.arange(1,(n/2)+1)\n",
    "    frek = np.reshape(frek, (frek.size,1)) #transpose frek to column array \n",
    "        \n",
    "    #if avg=1, then average frek and Pyy before taking spectra\n",
    "    if avg == 1: \n",
    "        #initialize empty 1D arrays\n",
    "        ff = np.zeros((1,p-1)).flatten()\n",
    "        pp = np.zeros((1,p-1)).flatten()\n",
    "        #for loop takes mean of ranges between 2^0 and 2^p\n",
    "        #output is arrays ff and pp where each element of the array is average of ranges i.e. [avg(2^0-(2^1)-1), avg(2^1-(2^2)-1), ..., avg(2^(p-1)-(2^p)-1)]\n",
    "        for i in range(1,p):\n",
    "            #each element in ff is mean of frek from 2^(i-1) to (2^i) - 1 until i = p\n",
    "            ff[i-1]=np.mean(frek[2**(i-1)-1:2**i-1])\n",
    "            #each element in pp is mean of Pyy from 2^(i-1) to (2^i) - 1 until i = p\n",
    "            pp[i-1]=np.mean(Pyy[2**(i-1)-1:2**i-1])\n",
    "        #clear Pyy and frek and set value to pp and ff omitting first index\n",
    "        Pyy=[] #clear Pyy\n",
    "        Pyy = pp[1:len(pp)]\n",
    "        Pyy = np.reshape(Pyy, (Pyy.size,1)) #convert into 2D array\n",
    "        frek=[] #clear frek\n",
    "        frek=ff[1:len(pp)]\n",
    "        frek = np.reshape(frek,(frek.size,1)) #convert into 2D array\n",
    "        #now spectra will be of average frek and Pyy values, not all values\n",
    "      \n",
    "\n",
    "    #find where Pyy has values of 0, set those values to 0.00001 before taking log\n",
    "    k = np.where(Pyy==0)\n",
    "    if len(k)!=0: #if there are values where Pyy = 0\n",
    "        for kk in range(1,len(k)+1):\n",
    "            Pyy[k[kk-1]] = 0.00001\n",
    "            \n",
    "    #take natural log of Pyy and frek\n",
    "    lgPyy = np.log(Pyy)\n",
    "    lgfrek = np.log(frek)\n",
    "    \n",
    "    #power spectral density (PSD) plot \n",
    "    #plt.title('PSD Before High Freq Excluded')\n",
    "    #plt.semilogx(frek, Pyy)\n",
    "    #plt.yscale('log')\n",
    "    #plt.xlabel('Frequency')\n",
    "    #plt.ylabel('Power')\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    #compute linear regression of PSD\n",
    "    #curvefit returns an array of 2 values: (1) slope from lin regression, (2) correlation coeff from lin regression\n",
    "    curvefit = Linreg(lgfrek,lgPyy)\n",
    "    #set result values to curvefit results (according to indices outlined in function definition)\n",
    "    result[2] = curvefit[0,0]*-1  #Beta has opposite sign as slope \n",
    "    result[1] = curvefit[1,0]   #Correlation coeff\n",
    "    #calculate Hurst coefficient based on value of Beta\n",
    "    if result[2]<1: #if Beta is less than 1, then Hurst coefficient is: \n",
    "        result[0] = (result[2]+1)/2 #signal is fGn, H_PSD = (Beta + 1)/2\n",
    "    elif result[2]>1: #if Beta is greater than 1, then Hurst coefficient is: \n",
    "        result[0] = (result[2]-1)/2 #signal is fBm, H_PSD = (Beta - 1)/2\n",
    "    elif result[2]==1: #if Beta is equal to 1, set Hurst to infinity\n",
    "        result[0] = inf \n",
    "        \n",
    "    #results 0,1,2 are the Hurst coeff, correlation coeff, and Beta of the raw signal (before high freqs excluded)\n",
    "\n",
    "\n",
    "    return result #result is array of the 6 values (results[0] to results[5])\n",
    "\n",
    "def Stdn(x):\n",
    "    '''Standard deviation computes the \"population\" standard deviation, that is, it is \n",
    "    normalized by N, where N is the sequence length'''\n",
    "    mikro = np.mean(x) #mean of time series\n",
    "    \n",
    "    n = len(x) #length of time series\n",
    "    result = (np.sum((x-mikro)**2)/n)**0.5 #standard deviation formula \n",
    "   \n",
    "    return result\n",
    "\n",
    "def Disper(ts, p):\n",
    "    '''This function performs dispersional analysis on time series. Dispersion is a measure\n",
    "    of how much a distribution is stretched or squeezed.\n",
    "    result[0]: Hurst coefficient\n",
    "    result[1]: correlation coefficient (r) from linear regression'''\n",
    "    used = p -3 #the number of data points used in curve fit, excludes 1/2,1/4,1/8 frequencies\n",
    "   \n",
    "    lgsd = np.empty((1,used)).flatten() #initialize empty arrays for for-loop\n",
    "    lgn = np.empty((1,used)).flatten()\n",
    "    for i in range(1,used+1): #increment by orders of 2 (scales)\n",
    "        lgsd[i-1] = np.log(Stdn(ts)) #calculates log of standard deviation of each scale\n",
    "        lgn[i-1] = np.log(2**i) #natural log of bin size\n",
    "        tsid = (ts[0:len(ts)-1:2] + ts[1:len(ts):2])/2 #odd time-points + even time-points/2 (avg between points)\n",
    "        ts = []\n",
    "        ts = tsid #reset ts to new time-signal which is half the length and the average between points.\n",
    "        tsid = []\n",
    "    #lgsd is the natural log of the standard deviation\n",
    "    #lgn is the natural log of the bin size\n",
    "    curvefit = Linreg(lgn, lgsd) #compute linear regression \n",
    "    result = np.empty((1,2)).flatten() #initialize empty results vector\n",
    "    result[0] = 1 + curvefit[0] #Hurst coeff - 1 + slope of linear regression\n",
    "    result[1] = curvefit[1] #correlation coeff of linear regression \n",
    "    return result\n",
    "\n",
    "def Bdswv(ts, p): \n",
    "    '''This function performs bridge detrended scaled window variance analysis on an fBm \n",
    "    time series'''\n",
    "    #ignored: column 0 is length, column 1 is smallest bin size, column 2 is largest bin size\n",
    "    #these are the smallest/largest bins that will be ignored\n",
    "    #for longer time series (larger p), more bins are ignored\n",
    "    ignored = np.matrix([[6, 1, 0], [7, 1, 0], [8, 1, 0], [9, 2, 2], [10, 2, 3], [11, 2, 4], [12, 2, 4], [13, 2, 5], [14, 3, 6], [15, 3, 7], [16, 3, 7], [17, 3, 7], [18, 3, 7]])\n",
    "    #while loop stops once p is equal to a length in column 0\n",
    "    #smallest and largest are the values in the same row as this length \n",
    "    i = 1\n",
    "    while p >= ignored[i-1,0]:\n",
    "        smallest = ignored[i-1,1]\n",
    "        largest = ignored[i-1,2]\n",
    "        i = i + 1\n",
    "    #smallest: ignore these smallest bin sizes\n",
    "    #largest: ignore these largest bin sizes\n",
    "    #example: p = 10, smallest is 2, largest is 3\n",
    "    used1 = smallest + 1 #beginning of range of used bins\n",
    "    used2 = p - largest #end of range of used bins\n",
    "    n = len(ts)\n",
    "    #example: p = 10, used1 = 2+1=3, used2 = 10-3 = 7 \n",
    "     \n",
    "    #initialize empty arrays for range of used bins    \n",
    "    lgsd = np.zeros(used2-used1+1)\n",
    "    lgn = np.zeros(used2-used1+1)\n",
    "    #for loop goes through every bin in used range (ex bins 3-7 for p =10)\n",
    "    for i in range(used1, used2 + 1):\n",
    "        counter = 0\n",
    "        sd = [] \n",
    "        #next for loop runs until n-i, incrementing by 2^i\n",
    "        #for p = 10, this will be 0 - 1024-2 incrementing by 2^3 for i = 3\n",
    "        for j in range(0, n-i +1, 2**i): \n",
    "            tsmod = ts[j:j+2**i] #splices ts into 2^i splices\n",
    "            # p = 10, then splice into ts[0,7], ts[8,15] etc \n",
    "            # tsmod is a bin (different every time loop runs)\n",
    "            tsmod = np.reshape(tsmod,(tsmod.size,1)) #make into 2D array\n",
    "            tsid = Bridge(tsmod) #apply bridge to bin (tsmod)\n",
    "            tsmod = []\n",
    "            sd.append(np.std(tsid, ddof=1)) #take standard deviation of bridged bin\n",
    "            tsid=[]\n",
    "    \n",
    "        lgsd[i-used1] = np.log(np.mean(sd)) #natural log of average standard deviation over all bins\n",
    "        lgn[i-used1] = np.log(2**i) #natural log of bin size\n",
    "    \n",
    "    curvefit = Linreg(lgn, lgsd) #perform linear regression on lgn and lgsd\n",
    "    result = np.empty((1,2)).flatten()\n",
    "    result[0] = curvefit[0] #slope from linear regression\n",
    "    result[1] = curvefit[1] #correlation coeff from linear regression\n",
    "\n",
    "    return result\n",
    "   \n",
    "    \n",
    "def FracTool(ts):\n",
    "    '''This function will aid time series analysis using the concept of statistical fractals.\n",
    "     This code is adapted from A. Eke, P. Hermán, J. B. Bassingthwaighte, G. M. Raymond, D. B. Percival, \n",
    "     M. Cannon, I. Balla, and C. Ikrényi. Physiological time series: distinguishing \n",
    "     fractal noises from motions. Pflügers Archiv European Journal of \n",
    "     Physiology,4394):403-415, 2000. \n",
    "     FracTool determines: \n",
    "     1) The signal class of the time series according to the fGn/fBm model\n",
    "     2) The Hurst coefficients for the fGn or fBm time series\n",
    "     The input \"ts\" is a time series of a single column of data points\n",
    "     The output of the function is an array of two results\n",
    "     result[0]: the signal class where: 0 = fGn, 1 = fGn/fBm boundary, 2 = fBm, 3 = outside model\n",
    "     result[1]: the final computed Hurst coefficient\n",
    "     '''\n",
    "    \n",
    "    assert (len(ts) !=0), 'time series is empty' #ensures time series is not empty\n",
    "\n",
    "    #initialization \n",
    "    H_PSD = -1\n",
    "    H_Disp = -1\n",
    "    H_bdSWV = -1\n",
    "    H_fGn = -1\n",
    "    H_fBm = -1\n",
    "    Hurst = -1\n",
    "    sig_class = None \n",
    "    \n",
    "    #sig_class = 0: fGn signal\n",
    "    #sig_class = 1: fGn/fBm boundary\n",
    "    #sig_class = 2: fBm signal\n",
    "    #sig_class = 3: outside fGn/fBm model\n",
    "    \n",
    "    #parameters \n",
    "    n=len(ts) #length of time series input\n",
    "    #print('Number of raw time-points = ', n)\n",
    "    i = 1\n",
    "    while n >= 2**i: #calculates the closest 2^i value in n \n",
    "        i += 1\n",
    "    p = i - 1\n",
    "    tsid = ts[0:2**p] #splices time series to exclue points after 2^p\n",
    "    #print('Number of time-points after 2^p splice =', 2**p)\n",
    "    del ts #delete signal before splice (the raw time series)\n",
    "    signal_mean = np.mean(tsid) #get mean of spliced time series\n",
    "    #print('Mean of time series = ', signal_mean)\n",
    "    n = len(tsid) #update n to length of tsid\n",
    "    \n",
    "    #get Beta value using lowPSDw,e method (w:windowing, e:endmatching, low:excluding high frequencies)\n",
    "    #apply parabolic window, then bridge detrend the time series\n",
    "    #calculate spectra estimates excluding frequencies between 1/8 and 1/2\n",
    "    #Beta is the slope of the regression of the spectral estimates\n",
    "    result = Spec(Bridge(Window(tsid)),p,0)   \n",
    "    \n",
    "    #the value of beta determines the method used to calculate the Hurst coefficient\n",
    "    if result[2,0]<0.38 and result[2,0]>-1: \n",
    "        # if -1<Beta<0.38, then signal is fGn \n",
    "        #apply PSD and dispersion method on signal to calculate Hurst coefficient\n",
    "        H_PSD = (result[2,0]+1)/2 #PSD method\n",
    "        temp = Disper(tsid,p)\n",
    "        H_Disp = temp[0] #dispersion method\n",
    "        H_fGn = (H_PSD+H_Disp)/2 #average of both methods gives final H value\n",
    "        Hurst = H_fGn\n",
    "        sig_class = 0 #signal is fGn \n",
    "        \n",
    "    elif result[2,0]>=0.38 and result[2,0]<=1.04:\n",
    "        # if 0.38<=Beta<=1.04, signal is not classifiable\n",
    "        # need to apply SSC method to distinguish class\n",
    "        # the SSC method calculates the cumulative sum of the time series and then uses bdSWV to calculate H from the cumulant series\n",
    "        # the Hurst coefficient is then used to distinguish signal class\n",
    "        ts = np.cumsum(tsid) #take cumulative sum of raw time series\n",
    "        temp = Bdswv(ts,p) #apply bdSWV method to cumulant series to get Hurst\n",
    "        HH = temp[0] #Hurst of cumulant sum \n",
    "        if HH < 0.8: #signal is fGn\n",
    "            H_PSD = (result[2,0]+1)/2 #Hurst calculated by PSD\n",
    "            temp = Disper(tsid, p) #apply dispersion to raw time series\n",
    "            H_Disp = temp[0] #Hurst calculated by dispersion method\n",
    "            H_fGn = (H_PSD + H_Disp)/2 #avg of Hurst calculated by both methods\n",
    "            Hurst = H_fGn\n",
    "            sig_class = 0 #signal is fGn class\n",
    "        elif HH>0.8 and HH<1: #cannot classify signal\n",
    "            sig_class = 1 #signal falls in fGn/fBm boundary\n",
    "            Hurst = None \n",
    "        elif HH>1: #signal is fBm\n",
    "            H_PSD = (result[2,0]-1)/2 #Hurst calculated by PSD\n",
    "            temp = Bdswv(ts,p) #apply Bdswv to cumulant time series\n",
    "            H_bdSWV = temp[0] #Hurst calculated \n",
    "            H_fBm = (H_PSD+H_bdSWV)/2 #avg of Hurst calculated by both methods\n",
    "            Hurst = H_fBm\n",
    "            sig_class = 2 #signal is fBm \n",
    "    \n",
    "    elif result[2,0]>1.04 and result[2,0]<3: \n",
    "        #if 1.04<Beta<3, signal is fBm\n",
    "        #apply PSD and bdSWV to calculate Hurst, then take average of H values\n",
    "        H_PSD = (result[2,0]-1)/2 #Hurst calculated by PSD\n",
    "        temp = Bdswv(tsid,p) \n",
    "        H_bdSWV = temp[0] #Hurst calculated by bdSWV\n",
    "        H_fBm = (H_PSD + H_bdSWV)/2 #avg of both methods giving final Hurst\n",
    "        Hurst = H_fBm\n",
    "        sig_class = 2 #signal is fBm\n",
    "    \n",
    "    else:\n",
    "        sig_class = 3\n",
    "        Hurst = None \n",
    "    \n",
    "    #print statements: output of code\n",
    "    #recall parameters initialized to -1\n",
    "    #print('Output Parameters of Fractal Analysis of Time Series:')\n",
    "    #print('Beta = ', result[5,0])\n",
    "    #print('Correlation coefficient = ', result[4,0])\n",
    "    #if sig_class == 0:\n",
    "    #    print('Signal is class 0: fGn')\n",
    "    #elif sig_class == 1:\n",
    "    #    print('Signal is class 1: in fGn/fBm boundary')\n",
    "    #elif sig_class == 2: \n",
    "    #    print('Signal is class 2: fBm')\n",
    "    #elif sig_class == 3: \n",
    "    #    print('Signal is class 3: outside the fGn/fBm model')\n",
    "    #print('H_PSD = ', H_PSD)\n",
    "    #print('H_Disp = ', H_Disp)\n",
    "    #print('H_bdSWV = ', H_bdSWV)\n",
    "    #print('H_fGn = ', H_fGn)\n",
    "    #print('H_fBm = ', H_fBm)\n",
    "    \n",
    "    #create empty results array for FracTool outputs\n",
    "    #result = np.zeros((1,2)).flatten()\n",
    "    #assign values to result array\n",
    "\n",
    "    #result[0] = sig_class #signal class\n",
    "    #result[1] = Hurst #final Hurst coefficient\n",
    "    \n",
    "    return [sig_class, Hurst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bdswv(ts, p): \n",
    "    '''This function performs bridge detrended scaled window variance analysis on an fBm \n",
    "    time series'''\n",
    "    #ignored: column 0 is length, column 1 is smallest bin size, column 2 is largest bin size\n",
    "    #these are the smallest/largest bins that will be ignored\n",
    "    #for longer time series (larger p), more bins are ignored\n",
    "    ignored = np.matrix([[6, 1, 0], [7, 1, 0], [8, 1, 0], [9, 2, 2], [10, 2, 3], [11, 2, 4], [12, 2, 4], [13, 2, 5], [14, 3, 6], [15, 3, 7], [16, 3, 7], [17, 3, 7], [18, 3, 7]])\n",
    "    #while loop stops once p is equal to a length in column 0\n",
    "    #smallest and largest are the values in the same row as this length \n",
    "    i = 1\n",
    "    while p >= ignored[i-1,0]:\n",
    "        smallest = ignored[i-1,1]\n",
    "        largest = ignored[i-1,2]\n",
    "        i = i + 1\n",
    "    #smallest: ignore these smallest bin sizes\n",
    "    #largest: ignore these largest bin sizes\n",
    "    #example: p = 10, smallest is 2, largest is 3\n",
    "    used1 = smallest + 1 #beginning of range of used bins\n",
    "    print('used 1', used1)\n",
    "    used2 = p - largest #end of range of used bins\n",
    "    print('used 2', used2)\n",
    "    n = len(ts)\n",
    "    print('length', n)\n",
    "    #example: p = 10, used1 = 2+1=3, used2 = 10-3 = 7 \n",
    "     \n",
    "    #initialize empty arrays for range of used bins    \n",
    "    lgsd = np.zeros(used2-used1+1)\n",
    "    lgn = np.zeros(used2-used1+1)\n",
    "    #for loop goes through every bin in used range (ex bins 3-7 for p =10)\n",
    "    for i in range(used1, used2 + 1):\n",
    "        counter = 0\n",
    "        sd = [] \n",
    "        #next for loop runs until n-i, incrementing by 2^i\n",
    "        #for p = 10, this will be 0 - 1024-2 incrementing by 2^3 for i = 3\n",
    "        for j in range(0, n-i +1, 2**i): \n",
    "            tsmod = ts[j:j+2**i] #splices ts into 2^i splices\n",
    "            # p = 10, then splice into ts[0,7], ts[8,15] etc \n",
    "            # tsmod is a bin (different every time loop runs)\n",
    "            tsmod = np.reshape(tsmod,(tsmod.size,1)) #make into 2D array\n",
    "            tsid = Bridge(tsmod) #apply bridge to bin (tsmod)\n",
    "            tsmod = []\n",
    "            sd.append(np.std(tsid, ddof=1)) #take standard deviation of bridged bin\n",
    "            tsid=[]\n",
    "    \n",
    "        lgsd[i-used1] = np.log(np.mean(sd)) #natural log of average standard deviation over all bins\n",
    "        lgn[i-used1] = np.log(2**i) #natural log of bin size\n",
    "    \n",
    "    curvefit = Linreg(lgn, lgsd) #perform linear regression on lgn and lgsd\n",
    "    result = np.empty((1,2)).flatten()\n",
    "    result[0] = curvefit[0] #slope from linear regression\n",
    "    result[1] = curvefit[1] #correlation coeff from linear regression\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used 1 3\n",
      "used 2 7\n",
      "length 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.69360134, 0.99783284])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loads fbm signal of known Hurst coeffecient \n",
    "#Hurst coeff is 0.7 and signal has 1024 timepoints\n",
    "fBm_knownH = np.loadtxt(fname=\"Test_Signals/sig_fbm_knownH.csv\", delimiter =\",\")\n",
    "#turn 1D array into 2D array and transpose so single column vector \n",
    "fBm_knownH_T = np.reshape(fBm_knownH,(fBm_knownH.size, 1))\n",
    "#function call\n",
    "Bdswv(fBm_knownH_T, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
