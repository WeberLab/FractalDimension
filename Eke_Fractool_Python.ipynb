{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "def Window(ts):\n",
    "    '''This function applies a parabolic window to the signal input'''\n",
    "    n = len(ts) #n is length of time series\n",
    "    W = np.zeros((n,1)) #initialize empty array\n",
    "    #create parabola from 0 to length n\n",
    "    for j in np.arange(0,n):\n",
    "        W[j] = 1 - np.power((2*(j + 1)/(n+1)-1),2)\n",
    "    #multiply parabola and signal to get windowed signal (result)\n",
    "    result = ts * W \n",
    "    return result\n",
    "\n",
    "def Bridge(ts):\n",
    "    '''This function applies the bridge detrended method to the signal input'''\n",
    "    n = len(ts)\n",
    "    #points is the length of the time series from n-1 to 0 (backwards i.e. n-1, n-2,...0)\n",
    "    points = np.arange(n-1, -1, -1).reshape(1,n)\n",
    "    #line connecting first and last point\n",
    "    line = ((ts[0]-ts[n-1])*points/(n-1))+ts[n-1]\n",
    "    line = line.transpose() #transposes line from row to column array\n",
    "    #subtract line from time series to return bridge detrended signal (result)\n",
    "    result = ts - line\n",
    "    return result \n",
    "\n",
    "def Linreg(x,y):\n",
    "    '''This function calculates the slope and correlation coeff of a linear fit\n",
    "    Result[0]: Slope\n",
    "    Result[1]: Correlation coefficient'''\n",
    "    #calculate mean of x and y (lgfrek and lgPyy when called in FracTool)\n",
    "    mikro = np.mean(x) #mean of lgfrek\n",
    "    nu = np.mean(y) #mean of lgPyy\n",
    "    mikro_sub = x - mikro #subtract lgfrek mean from lgfrek array \n",
    "    nu_sub = y - nu #subtract lgPyy mean from lgPyy\n",
    "    #multiply arrays and add sum of elements \n",
    "    Qxy = np.sum(mikro_sub*nu_sub)\n",
    "    Qx = sum(mikro_sub**2) #sum of sqaured differences of lgfrek\n",
    "    Qy = sum((nu_sub**2)) #sum of squared differences of lgPyy\n",
    "    result = np.empty([2,1]) #initialize empty result array\n",
    "    result[0] = Qxy/Qx #slope of linear regression\n",
    "    result[1] = Qxy/(Qx*Qy)**0.5 #correlation coefficient of linear regression\n",
    "    \n",
    "    return result\n",
    " \n",
    "    \n",
    "\n",
    "def Spec(ts, p, avg): \n",
    "    '''This function performs a spectral analysis of the time series\n",
    "    where ts is the time series, p is the nth power of 2 where 2^n<=length\n",
    "    of time series. If avg=0, then spectra for all, if avg=1, then spectra avg.\n",
    "    An array of the following results will be returned.\n",
    "    result(0): Hurst coefficient\n",
    "    result(1): correlation coefficient\n",
    "    result(2): beta from Fourier analysis\n",
    "    result(3): Hurst coefficient (high freq excluded)\n",
    "    result(4): correlation coefficient (high freq excluded)\n",
    "    result(5): beta from Fourier analysis (high freq excluded)'''\n",
    "    #initialize empty array for results outlined above\n",
    "    result = np.empty([6,1])\n",
    "    f = 1\n",
    "    n = 2**p\n",
    "    #compute the estimated power of time series (Pyy)\n",
    "    #compute the discrete fourier transform of time series \n",
    "    Y = scipy.fftpack.fft(ts.flatten()) #time series needs to be 1D (flattened from 2D)\n",
    "    Pyy = Y*np.divide(Y.conj(),n) #divide the conjucate of the fourier transform by n \n",
    "    Pyy = Pyy[0:int(n/2)] #splice array to only include have first half (it is symmetric)\n",
    "    Pyy = np.reshape(Pyy, (Pyy.size,1)) #convert Pyy to column array\n",
    "    \n",
    "    #clear Y and y arrays\n",
    "    Y = []\n",
    "    y = []\n",
    "    \n",
    "    #generate array of frequencies from 0 to 0.5 (frek)\n",
    "    frek = f/n*np.arange(1,(n/2)+1)\n",
    "    frek = np.reshape(frek, (frek.size,1)) #transpose frek to column array \n",
    "        \n",
    "    #if avg=1, then average frek and Pyy before taking spectra\n",
    "    if avg == 1: \n",
    "        #initialize empty 1D arrays\n",
    "        ff = np.zeros((1,p-1)).flatten()\n",
    "        pp = np.zeros((1,p-1)).flatten()\n",
    "        for i in range(1,p):\n",
    "            #each element in ff is mean of frek from 2^(i-1) to (2^i) - 1 until i = p\n",
    "            ff[i-1]=np.mean(frek[2**(i-1)-1:2**i-1])\n",
    "            #each element in pp is mean of Pyy from 2^(i-1) to (2^i) - 1 until i = p\n",
    "            pp[i-1]=np.mean(Pyy[2**(i-1)-1:2**i-1])\n",
    "        #clear Pyy and frek and set value to pp and ff omitting first index\n",
    "        Pyy=[] #clear Pyy\n",
    "        Pyy = pp[1:len(pp)]\n",
    "        Pyy = np.reshape(Pyy, (Pyy.size,1)) #convert into 2D array\n",
    "        frek=[] #clear frek\n",
    "        frek=ff[1:len(pp)]\n",
    "        frek = np.reshape(frek,(frek.size,1)) #convert into 2D array\n",
    "        #now spectra will be of average, not all (when avg=0)\n",
    "      \n",
    "\n",
    "    #find where Pyy has values of 0, set those values to 0.00001 before taking log\n",
    "    k = np.where(Pyy==0)\n",
    "    if len(k)!=0: #if there are values where Pyy = 0\n",
    "        for kk in range(1,len(k)+1):\n",
    "            Pyy[k[kk-1]] = 0.00001\n",
    "            \n",
    "    #take natural log of Pyy and frek\n",
    "    lgPyy = np.log(Pyy)\n",
    "    lgfrek = np.log(frek)\n",
    "    \n",
    "    #power spectral density (PSD) plot \n",
    "    #plt.plot(lgfrek,lgPyy)\n",
    "    #plt.title('PSD Before High Freq Excluded')\n",
    "    #plt.show()\n",
    "    \n",
    "    #compute linear regression of PSD\n",
    "    #curvefit returns an array of 2 values: (1) slope from lin regression, (2) correlation coeff from lin regression\n",
    "    curvefit = Linreg(lgfrek,lgPyy)\n",
    "    #set result values to curvefit results (according to indices outlined in function definition)\n",
    "    result[2] = curvefit[0,0]*-1  #Beta has opposite sign as slope \n",
    "    result[1] = curvefit[1,0]   #Correlation coeff\n",
    "    #calculate Hurst coefficient based on value of Beta\n",
    "    if result[2]<1: #if Beta is less than 1\n",
    "        result[0] = (result[2]+1)/2\n",
    "    elif result[2]>1: #if Beta is greater than 1\n",
    "        result[0] = (result[2]-1)/2\n",
    "    elif result[2]==1: #if Beta is equal to 1, set Hurst to infinity\n",
    "        result[0] = inf \n",
    "   \n",
    "    #if avg=1, then exclue the last two values of lgfrek and lgPyy and then perform linear regression\n",
    "    if avg == 1: \n",
    "        curvefit = Linreg(lgfrek[0:len(lgfrek)-2], lgPyy[0:len(lgPyy)-2])\n",
    "    \n",
    "    #if avg=0, exclude frequencies from 0.125Hz-0.5Hz and then perform linear regression \n",
    "    else:\n",
    "        curvefit = Linreg(lgfrek[0:int(np.floor(len(lgfrek)/4))],lgPyy[0:int(np.floor(len(lgPyy)/4))])\n",
    "    \n",
    "    #plot of PSD after high frequencies are excluded\n",
    "    #plt.plot(lgfrek[0:int(np.floor(len(lgfrek)/4))],lgPyy[0:int(np.floor(len(lgPyy)/4))])\n",
    "    #plt.title('PSD After High Freq Excluded')\n",
    "    #plt.show\n",
    "    \n",
    "    #results of curvefit with high frequencies excluded\n",
    "    result[5] = curvefit[0]*-1 #Beta\n",
    "    result[4] = curvefit[1] #correlation coefficient\n",
    "    \n",
    "    #determine Hurst coefficient from Beta found after excluding high frequencies\n",
    "    if result[5]<1: #if Beta is less than 1\n",
    "        result[3] = (result[5]+1)/2\n",
    "    elif result[5]>1: #if Beta is greater than 1\n",
    "        result[3] = (result[5]-1)/2\n",
    "    elif result[5]==1: #if Beta is equal to 1, set Hurst coefficient to infinity \n",
    "        result[0] = inf \n",
    "        \n",
    "    return result #result is array of 6 values\n",
    "\n",
    "def Stdn(x):\n",
    "    '''Standard deviation computes the \"population\" standard deviation, that is, it is \n",
    "    normalized by N, where N is the sequence length'''\n",
    "    mikro = np.mean(x) #mean of time series\n",
    "    \n",
    "    n = len(x) #length of time series\n",
    "    result = (np.sum((x-mikro)**2)/n)**0.5\n",
    "   \n",
    "    return result\n",
    "\n",
    "def Disper(ts, p):\n",
    "    '''This function performs dispersional analysis on time series. Dispersion is a measure\n",
    "    of how much a distribution is stretched or squeezed.\n",
    "    result[0]: Hurst coefficient\n",
    "    result[1]: correlation coefficient (r) from linear regression'''\n",
    "    used = p - 3 #the number of data points used in curve fit, excludes 1/2,1/4,1/8 frequencies\n",
    "   \n",
    "    lgsd = np.empty((1,used)).flatten() #initialize empty arrays for for-loop\n",
    "    lgn = np.empty((1,used)).flatten()\n",
    "    for i in range(1,used+1): #increment by orders of 2 (scales)\n",
    "        lgsd[i-1] = np.log(Stdn(ts)) #calculates log of standard deviation of each scale\n",
    "        lgn[i-1] = np.log(2**i) #natural log of bin size\n",
    "        tsid = (ts[0:len(ts)-1:2] + ts[1:len(ts):2])/2 #odd time-points + even time-points/2 (avg between points)\n",
    "        ts = []\n",
    "        ts = tsid #reset ts to new time-signal which is half the length and the average between points.\n",
    "        tsid = []\n",
    "    #lgsd is the natural log of the standard deviation\n",
    "    #lgn is the natural log of the bin size\n",
    "    curvefit = Linreg(lgn, lgsd) #compute linear regression \n",
    "    result = np.empty((1,2)).flatten() #initialize empty results vector\n",
    "    result[0] = 1 + curvefit[0] #Hurst coeff - 1 + slope of linear regression\n",
    "    result[1] = curvefit[1] #correlation coeff of linear regression \n",
    "    return result\n",
    "\n",
    "def Bdswv(ts, p): \n",
    "    '''This function performs bridge detrended scaled window variance analysis on an fBm \n",
    "    time series'''\n",
    "    #ignored: column 0 is length, column 1 is smallest bin size, column 2 is largest bin size\n",
    "    #these are the smallest/largest bins that will be ignored\n",
    "    #for longer time series (larger p), more bins are ignored\n",
    "    ignored = np.matrix([[6, 1, 0], [7, 1, 0], [8, 1, 0], [9, 2, 2], [10, 2, 3], [11, 2, 4], [12, 2, 4], [13, 2, 5], [14, 3, 6], [15, 3, 7], [16, 3, 7], [17, 3, 7], [18, 3, 7]])\n",
    "    #while loop stops once p is equal to a length in column 0\n",
    "    #smallest and largest are the values in the same row as this length \n",
    "    i = 1\n",
    "    while p >= ignored[i-1,0]:\n",
    "        smallest = ignored[i-1,1]\n",
    "        largest = ignored[i-1,2]\n",
    "        i = i + 1\n",
    "    #smallest: ignore these smallest bin sizes\n",
    "    #largest: ignore these largest bin sizes\n",
    "    #example: p = 10, smallest is 2, largest is 3\n",
    "    used1 = smallest + 1 #beginning of range of used bins\n",
    "    used2 = p - largest #end of range of used bins\n",
    "    n = len(ts)\n",
    "    #example: p = 10, used1 = 2+1=3, used2 = 10-3 = 7 \n",
    "     \n",
    "    #initialize empty arrays for range of used bins    \n",
    "    lgsd = np.zeros(used2-used1+1)\n",
    "    lgn = np.zeros(used2-used1+1)\n",
    "    #for loop goes through every bin in used range (ex bins 3-7 for p =10)\n",
    "    for i in range(used1, used2 + 1):\n",
    "        counter = 0\n",
    "        sd = [] \n",
    "        #next for loop runs until n-i, incrementing by 2^i\n",
    "        #for p = 10, this will be 0 - 1024-2 incrementing by 2^3 for i = 3\n",
    "        for j in range(0, n-i +1, 2**i): \n",
    "            tsmod = ts[j:j+2**i] #splices ts into 2^i splices\n",
    "            # p = 10, then splice into ts[0,7], ts[8,15] etc \n",
    "            # tsmod is a bin (different every time loop runs)\n",
    "            tsmod = np.reshape(tsmod,(tsmod.size,1)) #make into 2D array\n",
    "            tsid = Bridge(tsmod) #apply bridge to bin (tsmod)\n",
    "            tsmod = []\n",
    "            sd.append(np.std(tsid, ddof=1)) #take standard deviation of bridged bin\n",
    "            tsid=[]\n",
    "    \n",
    "        lgsd[i-used1] = np.log(np.mean(sd)) #natural log of average standard deviation over all bins\n",
    "        lgn[i-used1] = np.log(2**i) #natural log of bin size\n",
    "    \n",
    "    curvefit = Linreg(lgn, lgsd) #perform linear regression on lgn and lgsd\n",
    "    result = np.empty((1,2)).flatten()\n",
    "    result[0] = curvefit[0] #slope from linear regression\n",
    "    result[1] = curvefit[1] #correlation coeff from linear regression\n",
    "\n",
    "    return result\n",
    "   \n",
    "    \n",
    "def FracTool(ts):\n",
    "    '''This function will aid time series analysis using the concept \n",
    "     of statistical fractals.\n",
    "     This code is adapted from A. Eke, P. Hermán, J. B. Bassingthwaighte, G. M. Raymond, D. B. Percival, \n",
    "     M. Cannon, I. Balla, and C. Ikrényi. Physiological time series: distinguishing \n",
    "     fractal noises from motions. Pflügers Archiv European Journal of \n",
    "     Physiology,4394):403-415, 2000. \n",
    "     Fractool determines: \n",
    "     1) The signal class of the time series according to the fGn/fBm model\n",
    "     2) The Hurst coefficients for the fGn or fBm time series\n",
    "     The input ts is a time series of a single coloumn of data points'''\n",
    "    \n",
    "    assert (len(ts) !=0), 'time series is empty'\n",
    "    \n",
    "    #initialization \n",
    "    H_PSD = -1\n",
    "    H_Disp = -1\n",
    "    H_bdSWV = -1\n",
    "    H_fGn = -1\n",
    "    H_fBm = -1\n",
    "    sig_class = None \n",
    "    #sig_class = 0: fGn signal\n",
    "    #sig_class = 1: fGn/fBm boundary\n",
    "    #sig_class = 2: fBm signal\n",
    "    #sig_class = 3: outside fGn/fBm model\n",
    "    \n",
    "    #parameters \n",
    "    n=len(ts) #length of time series input\n",
    "    print('Number of raw time-points = ', n)\n",
    "    i = 1\n",
    "    while n >= 2**i: #calculates the closest 2^i value in n \n",
    "        i += 1\n",
    "    p = i - 1\n",
    "    tsid = ts[0:2**p] #splices time series to exclue points after 2^p\n",
    "    print('Number of time-points after 2^p splice =', 2**p)\n",
    "    del ts #delete signal before splice (the raw time series)\n",
    "    signal_mean = np.mean(tsid) #get mean of spliced time series\n",
    "    print('Mean of time series = ', signal_mean)\n",
    "    n = len(tsid) #update n to length of tsid\n",
    "    \n",
    "    #get Beta value using lowPSDw,e method (w:windowing, e:endmatching, low:excluding high frequencies)\n",
    "    #apply parabolic window, then bridge detrend the time series\n",
    "    #calculate spectra estimates excluding frequencies between 1/8 and 1/2\n",
    "    #Beta is the slope of the regression of the spectral estimates\n",
    "    result = Spec(Bridge(Window(tsid)),p,0)\n",
    "    #print statements are of results when excluding high frequencies\n",
    "    print('Beta = ', result[5,0])\n",
    "    print('Correlation coeff = ', result[4,0])\n",
    "    \n",
    "    #the value of beta determines the method used to calculate the Hurst coefficient\n",
    "    if result[5,0]<0.38 and result[5,0]>-1: \n",
    "        # if -1<Beta<0.38, then signal is fGn \n",
    "        #apply PSD and dispersion method on signal to calculate Hurst coefficient\n",
    "        H_PSD = (result[5,0]+1)/2 #PSD method\n",
    "        temp = Disper(tsid,p)\n",
    "        H_Disp = temp[0] #dispersion method\n",
    "        H_fGn = (H_PSD+H_Disp)/2 #average of both methods gives final H value\n",
    "        sig_class = 0 #signal is fGn \n",
    "        \n",
    "    elif result[5,0]>=0.38 and result[5,0]<=1.04:\n",
    "        # if 0.38<=Beta<=1.04, signal is not classifiable\n",
    "        # need to apply SSC method to distinguish class\n",
    "        # the SSC method calculates the cumulative sum of the time series and then uses bdSWV to calculate H from the cumulant series\n",
    "        # the Hurst coefficient is then used to distinguish signal class\n",
    "        ts = np.cumsum(tsid) #take cumulative sum of raw time series\n",
    "        temp = Bdswv(ts,p) #apply bdSWV method to cumulant series to get Hurst\n",
    "        HH = temp[0] #Hurst of cumulant sum \n",
    "        if HH < 0.8: #signal is fGn\n",
    "            H_PSD = (result[5]+1)/2 #Hurst calculated by PSD\n",
    "            temp = Disper(tsid, p) #apply dispersion to raw time series\n",
    "            H_Disp = temp[0] #Hurst calculated by dispersion method\n",
    "            H_fGn = (H_PSD + H_Disp)/2 #avg of Hurst calculated by both methods\n",
    "            sig_class = 0 #signal is fGn class\n",
    "        elif HH>0.8 and HH<1: #cannot classify signal\n",
    "            sig_class = 1 #signal falls in fGn/fBm boundary\n",
    "        elif HH>1: #signal is fBm\n",
    "            H_PSD = (result[5]-1)/2 #Hurst calculated by PSD\n",
    "            temp = Bdswv(ts,p) #apply Bdswv to cumulant time series\n",
    "            H_bdSWV = temp[0] #Hurst calculated \n",
    "            H_fBm = (H_PSD+H_bdSWV)/2 #avg of Hurst calculated by both methods\n",
    "            sig_class = 2 #signal is fBm \n",
    "    \n",
    "    elif result[5,0]>1.04 and result[5,0]<3: \n",
    "        #if 1.04<Beta<3, signal is fBm\n",
    "        #apply PSD and bdSWV to calculate Hurst, then take average of H values\n",
    "        H_PSD = (result[5,0]-1)/2 #Hurst calculated by PSD\n",
    "        temp = Bdswv(tsid,p) \n",
    "        H_bdSWV = temp[0] #Hurst calculated by bdSWV\n",
    "        H_fBm = (H_PSD + H_bdSWV)/2 #avg of both methods giving final Hurst\n",
    "        sig_class = 2 #signal is fBm\n",
    "    \n",
    "    else:\n",
    "        sig_class = 3\n",
    "    \n",
    "    #print statements: output of code\n",
    "    #recall parameters initialized to -1\n",
    "    if sig_class == 0:\n",
    "        print('Signal is class 0: fGn')\n",
    "    elif sig_class == 1:\n",
    "        print('Signal is class 1: in fGn/fBm boundary')\n",
    "    elif sig_class == 2: \n",
    "        print('Signal is class 2: fBm')\n",
    "    elif sig_class == 3: \n",
    "        print('Signal is class 3: outside the fGn/fBm model')\n",
    "    print('H_PSD = ', H_PSD)\n",
    "    print('H_Disp = ', H_Disp)\n",
    "    print('H_bdSWV = ', H_bdSWV)\n",
    "    print('H_fGn = ', H_fGn)\n",
    "    print('H_fBm = ', H_fBm)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of raw time-points =  317\n",
      "Number of time-points after 2^p splice = 256\n",
      "Mean of time series =  312.6308723297187\n",
      "Beta =  1.0152172943682591\n",
      "Correlation coeff =  -0.5321453014959694\n",
      "Signal is class 2: fBm\n",
      "H_PSD =  [0.00760865]\n",
      "H_Disp =  -1\n",
      "H_bdSWV =  1.0327504834892265\n",
      "H_fGn =  -1\n",
      "H_fBm =  [0.52017957]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:43: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "#Load signal from sample fMRI (SCI_Pilot_08)\n",
    "#these signals have a grey mask applied\n",
    "fbm_sample = np.loadtxt(fname=\"Test_Signals/sig_fbm_sample.csv\", delimiter =\",\")\n",
    "fgn_sample = np.loadtxt(fname=\"Test_Signals/sig_fGn_sample.csv\", delimiter =\",\")\n",
    "SSC_fbm_sample = np.loadtxt(fname=\"Test_Signals/sig_SSC_fBm_sample.csv\", delimiter =\",\")\n",
    "SSC_fgn_sample = np.loadtxt(fname=\"Test_Signals/sig_SSC_fgn_sample.csv\", delimiter =\",\")\n",
    "noclass_sample = np.loadtxt(fname=\"Test_Signals/sig_noclass_sample.csv\", delimiter =\",\")\n",
    "\n",
    "#turn 1D array into 2D array and transpose so single column vector \n",
    "fbm_sample_T = np.reshape(fbm_sample,(fbm_sample.size, 1))\n",
    "fgn_sample_T = np.reshape(fgn_sample,(fgn_sample.size, 1))\n",
    "SSC_fbm_sample_T = np.reshape(SSC_fbm_sample,(SSC_fbm_sample.size, 1))\n",
    "SSC_fgn_sample_T = np.reshape(SSC_fgn_sample,(SSC_fgn_sample.size, 1))\n",
    "noclass_sample_T = np.reshape(noclass_sample,(noclass_sample.size, 1))\n",
    "\n",
    "\n",
    "#functioncall\n",
    "FracTool(SSC_fbm_sample_T)\n",
    "\n",
    "\n",
    "#Loads fbm signal of known Hurst coeffecient \n",
    "#Hurst coeff is 0.7 and signal has 1024 timepoints\n",
    "fBm_knownH = np.loadtxt(fname=\"Test_Signals/sig_fbm_knownH.csv\", delimiter =\",\")\n",
    "#turn 1D array into 2D array and transpose so single column vector \n",
    "fBm_knownH_T = np.reshape(fBm_knownH,(fBm_knownH.size, 1))\n",
    "#function call\n",
    "#FracTool(fBm_knownH_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
